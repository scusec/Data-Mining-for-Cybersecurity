{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We’ll start by doing all necessary imports, and we’ll let our Jupyter Notebook know that it should display graphs and images in the notebook itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import urllib\n",
    "import sys\n",
    "import os\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The files we're about to use may take five minutes or more to download, so if you're following along by running the program in the corresponding notebook, feel free to start running the next few cells. In the meantime, let’s explore textual entailment in further detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.5.6 |Anaconda, Inc.| (default, Aug 26 2018, 16:05:27) [MSC v.1900 64 bit (AMD64)]\n",
      "123\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.version\n",
    "print(sys.version)\n",
    "print(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_zip_file = \"glove.6B.zip\"\n",
    "glove_vectors_file = \"glove.6B.50d.txt\"\n",
    "\n",
    "snli_zip_file = \"snli_1.0.zip\"\n",
    "snli_dev_file = \"snli_1.0_dev.txt\"\n",
    "snli_full_dataset_file = \"snli_1.0_train.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unzip_single_file(zip_file_name, output_file_name):\n",
    "    \"\"\"\n",
    "        If the outFile is already created, don't recreate\n",
    "        If the outFile does not exist, create it from the zipFile\n",
    "    \"\"\"\n",
    "    if not os.path.isfile(output_file_name):\n",
    "        with open(output_file_name, 'wb') as out_file:\n",
    "            with zipfile.ZipFile(zip_file_name) as zipped:\n",
    "                for info in zipped.infolist():\n",
    "                    if output_file_name in info.filename:\n",
    "                        with zipped.open(info) as requested_file:\n",
    "                            out_file.write(requested_file.read())\n",
    "                            return\n",
    "\n",
    "unzip_single_file(glove_zip_file, glove_vectors_file)\n",
    "unzip_single_file(snli_zip_file, snli_dev_file)\n",
    "# unzip_single_file(snli_zip_file, snli_full_dataset_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Now that we have our GloVe vectors downloaded, we can load them into memory, deserializing the space separated format into a Python dictionary:\n",
    "The program use the function of numpy to translate the glove_vectors_file into matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400000\n"
     ]
    }
   ],
   "source": [
    "glove_wordmap = {}\n",
    "count = 0\n",
    "with open(glove_vectors_file, \"r\",encoding='utf-8') as glove:\n",
    "    for line in glove:\n",
    "        name, vector = tuple(line.split(\" \", 1))\n",
    "        glove_wordmap[name] = np.fromstring(vector, sep=\" \")\n",
    "        count += 1\n",
    "    print(count)\n",
    "#         print(name,glove_wordmap[name])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Once we have our words, we need our input to contain entire sentences and process it through a neural network. Let's start with making the sequence:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sentence2sequence 函数通过\" \"将整个句子进行分词（英文的分词依靠空格）\n",
    "该函数将整个句子分为单独的一个个单词\n",
    "并将整个句子存入一个(n,d)的矩阵之中\n",
    "n为句子单词的个数，d为每个单词的长度？最大长度吧\n",
    "\n",
    "这是一个简单具有分词功能的函数，它根据句子的语序将整个句子分成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence2sequence(sentence):\n",
    "    \"\"\"\n",
    "     \n",
    "    - Turns an input sentence into an (n,d) matrix, \n",
    "        where n is the number of tokens in the sentence\n",
    "        and d is the number of dimensions each word vector has.\n",
    "        d是一个定值50，通过glove_wordmap这个从文件中读取的word_map映射，将一个单词映射成为一个50维浮点型数据\n",
    "        n是一个变化的值，根据这个句子中包含的单词的个数决定\n",
    "        该函数将通过“ ”将整个句子进行分词，然后通过golve_map映射，将单个单词转换为一个五十维的浮点向量\n",
    "        之后再放入模型中进行训练\n",
    "    \n",
    "      Tensorflow doesn't need to be used here, as simply\n",
    "      turning the sentence into a sequence based off our \n",
    "      mapping does not need the computational power that\n",
    "      Tensorflow provides. Normal Python suffices for this task.\n",
    "    \"\"\"\n",
    "    tokens = sentence.lower().split(\" \")\n",
    "    rows = []\n",
    "    words = []\n",
    "    #Greedy search for tokens\n",
    "    for token in tokens:\n",
    "        i = len(token)\n",
    "        while len(token) > 0 and i > 0:\n",
    "#             print(token)\n",
    "            word = token[:i]\n",
    "            if word in glove_wordmap:\n",
    "                rows.append(glove_wordmap[word])\n",
    "                words.append(word)\n",
    "                token = token[i:]\n",
    "            else:\n",
    "                i = i-1\n",
    "    #print(rows, words)\n",
    "#     j=0\n",
    "#     for line in rows:\n",
    "#         print((\"line %d:\" % j) + line)\n",
    "#         print(line)\n",
    "#         j += 1\n",
    "#     print(words)\n",
    "#     for word, row in zip(words, rows):\n",
    "#         print(len(word),len(row))\n",
    "#         for line1, line2 in zip(word, row):\n",
    "#             print(line1 , \":\", line2)\n",
    "    return rows, words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To better visualize the word vectorization process, and to see what the computer sees when it looks at a sentence, we can represent the vectors as images. Each row represents a single word, and the columns represent individual dimensions of the vectorized word.  The vectorizations are trained in terms of relationships to other words, and so what the representations actually mean is ambiguous.  The computer can understand this vector language, and that’s the most important part to us. Generally speaking, two vectors that contain similar colors in the same positions represent words that are similar in meaning.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"\\n\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "visualize函数是为了更好的展示由输入句子产生的矩阵\n",
    "将这个向量矩阵以图片的形式展示了出来"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def visualize(sentence):\n",
    "    rows, words = sentence2sequence(sentence)\n",
    "    mat = np.vstack(rows)\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    shown = ax.matshow(mat, aspect=\"auto\")\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    fig.colorbar(shown)\n",
    "    \n",
    "    ax.set_yticklabels([\"\"]+words)\n",
    "    plt.show()\n",
    "    \n",
    "visualize(\"The quick brown fox jumped over the lazy dog.\")\n",
    "visualize(\"The pretty flowers shone in the sunlight.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "Recurrent Neural Networks (also known as RNNs) are a sequence-learning tool for neural networks. This type of neural network has only one layer’s worth of hidden inputs, which is re-used for each input from the sequence, along with a “memory” that’s passed ahead to the next input’s calculations. These are calculated using matrix multiplication where the matrix indices are trained weights, just like they are in a fully-connected layer. \n",
    "\n",
    "The same calculations are repeated for each input in the sequence, meaning that a single “layer” of a recurrent neural network can be unrolled into many layers. In fact, there will be as many layers as there are inputs in the sequence. This allows the network to process a very complex sentence. TensorFlow includes its own implementation of a vanilla RNN cell, BasicRNNCell, which can be added to your TensorFlow graph as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通过RNN神经网络对模型进行训练，并且设置RNN模型层数为64\n",
    "并紧接着通过TensorFlow搭建我们的RNN模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_size = 64\n",
    "rnn = tf.contrib.rnn.BasicRNNCell(rnn_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "# Defining the constants for our network\n",
    "\n",
    "Since we aren’t going to use a vanilla RNN layer in our network, let's clear out the graph and add an LSTM layer, which TensorFlow also includes by default. Since this is going to be the first part of our actual network, let's also define all the constants we'll need for the network, which we'll talk about as they come up:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "设置相应的图的参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Constants setup\n",
    "max_hypothesis_length, max_evidence_length = 30, 30\n",
    "batch_size, vector_size, hidden_size = 128, 50, 64\n",
    "\n",
    "lstm_size = hidden_size\n",
    "\n",
    "weight_decay = 0.0001\n",
    "\n",
    "learning_rate = 1\n",
    "\n",
    "input_p, output_p = 0.5, 0.5\n",
    "\n",
    "training_iterations_count = 100000\n",
    "\n",
    "display_step = 10\n",
    "\n",
    "def score_setup(row):\n",
    "    convert_dict = {\n",
    "      'entailment': 0,\n",
    "      'neutral': 1,\n",
    "      'contradiction': 2\n",
    "    }\n",
    "    score = np.zeros((3,))\n",
    "    for x in range(1,6):\n",
    "        tag = row[\"label\"+str(x)]\n",
    "        if tag in convert_dict: score[convert_dict[tag]] += 1\n",
    "    return score / (1.0*np.sum(score))\n",
    "\n",
    "def fit_to_size(matrix, shape):\n",
    "    res = np.zeros(shape)\n",
    "    slices = [slice(0,min(dim,shape[e])) for e, dim in enumerate(matrix.shape)]\n",
    "    res[slices] = matrix[slices]\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "snli_1.0_dev.txt中存放了用于训练模型的数据，通过split_data_into_scores函数把这些用于训练的数据转换为向量矩阵生成训练集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data_into_scores():\n",
    "    import csv\n",
    "    with open(\"snli_1.0_dev.txt\",\"r\") as data:\n",
    "        train = csv.DictReader(data, delimiter='\\t')\n",
    "        evi_sentences = []\n",
    "        hyp_sentences = []\n",
    "        labels = []\n",
    "        scores = []\n",
    "        for row in train:\n",
    "            hyp_sentences.append(np.vstack(\n",
    "                    sentence2sequence(row[\"sentence1\"].lower())[0]))\n",
    "            evi_sentences.append(np.vstack(\n",
    "                    sentence2sequence(row[\"sentence2\"].lower())[0]))\n",
    "            labels.append(row[\"gold_label\"])\n",
    "            scores.append(score_setup(row))\n",
    "        \n",
    "        hyp_sentences = np.stack([fit_to_size(x, (max_hypothesis_length, vector_size))\n",
    "                          for x in hyp_sentences])\n",
    "        evi_sentences = np.stack([fit_to_size(x, (max_evidence_length, vector_size))\n",
    "                          for x in evi_sentences])\n",
    "                                 \n",
    "        return (hyp_sentences, evi_sentences), labels, np.array(scores)\n",
    "    \n",
    "data_feature_list, correct_values, correct_scores = split_data_into_scores()\n",
    "\n",
    "l_h, l_e = max_hypothesis_length, max_evidence_length\n",
    "N, D, H = batch_size, vector_size, hidden_size\n",
    "l_seq = l_h + l_e\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll also reset the graph to not include the RNN cell we added earlier, since we won't be using that for this network:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With both those out of the way, we can define our LSTM using TensorFlow as follows:\n",
    "LSTM：长短期记忆网络，是一种特殊的RNN网络类型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = tf.contrib.rnn.BasicLSTMCell(lstm_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The loss of certain pieces of crucial memory means that complicated relationships required for first order logic have a harder time forming with dropout, and so for our LSTM layer we’ll skip using dropout on internal gates, instead using it on everything else. Thankfully, this is the default implementation of Tensorflow’s DropoutWrapper for recurrent layers:\n",
    "使用LSTM的原因\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_drop =  tf.contrib.rnn.DropoutWrapper(lstm, input_p, output_p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "With all the explanations out of the way, we can finish up our model. The first step is tokenizing and using our GloVe dictionary to turn the two input sentences into a single sequence of vectors. Since we can’t effectively use dropout on information that gets passed within an LSTM, we’ll use dropout on features from words, and on final output instead -- effectively using dropout on the first and last layers from the unrolled LSTM network portions. \n",
    "\n",
    "The final output from the LSTMs will be passed into a set of fully connected layers, and then from that we’ll get a single real-valued score that indicates how strong each of the kinds of entailment are, which we use to select our final result and our confidence in that result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义用于训练模型的必要参数以及相应的参数解读"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# N: The number of elements in each of our batches, \n",
    "#   which we use to train subsets of data for efficiency's sake.\n",
    "# l_h: The maximum length of a hypothesis, or the second sentence.  This is\n",
    "#   used because training an RNN is extraordinarily difficult without \n",
    "#   rolling it out to a fixed length.\n",
    "# l_e: The maximum length of evidence, the first sentence.  This is used\n",
    "#   because training an RNN is extraordinarily difficult without \n",
    "#   rolling it out to a fixed length.\n",
    "# D: The size of our used GloVe or other vectors.\n",
    "hyp = tf.placeholder(tf.float32, [N, l_h, D], 'hypothesis')\n",
    "evi = tf.placeholder(tf.float32, [N, l_e, D], 'evidence')\n",
    "y = tf.placeholder(tf.float32, [N, 3], 'label')\n",
    "# hyp: Where the hypotheses will be stored during training.\n",
    "# evi: Where the evidences will be stored during training.\n",
    "# y: Where correct scores will be stored during training.\n",
    "\n",
    "# lstm_size: the size of the gates in the LSTM, \n",
    "#    as in the first LSTM layer's initialization.\n",
    "lstm_back = tf.contrib.rnn.BasicLSTMCell(lstm_size)\n",
    "# lstm_back:  The LSTM used for looking backwards \n",
    "#   through the sentences, similar to lstm.\n",
    "\n",
    "# input_p: the probability that inputs to the LSTM will be retained at each\n",
    "#   iteration of dropout.\n",
    "# output_p: the probability that outputs from the LSTM will be retained at \n",
    "#   each iteration of dropout.\n",
    "lstm_drop_back = tf.contrib.rnn.DropoutWrapper(lstm_back, input_p, output_p)\n",
    "# lstm_drop_back:  A dropout wrapper for lstm_back, like lstm_drop.\n",
    "\n",
    "\n",
    "fc_initializer = tf.random_normal_initializer(stddev=0.1) \n",
    "# fc_initializer: initial values for the fully connected layer's weights.\n",
    "# hidden_size: the size of the outputs from each lstm layer.  \n",
    "#   Multiplied by 2 to account for the two LSTMs.\n",
    "fc_weight = tf.get_variable('fc_weight', [2*hidden_size, 3], \n",
    "                            initializer = fc_initializer)\n",
    "# fc_weight: Storage for the fully connected layer's weights.\n",
    "fc_bias = tf.get_variable('bias', [3])\n",
    "# fc_bias: Storage for the fully connected layer's bias.\n",
    "\n",
    "# tf.GraphKeys.REGULARIZATION_LOSSES:  A key to a collection in the graph\n",
    "#   designated for losses due to regularization.\n",
    "#   In this case, this portion of loss is regularization on the weights\n",
    "#   for the fully connected layer.\n",
    "tf.add_to_collection(tf.GraphKeys.REGULARIZATION_LOSSES, \n",
    "                     tf.nn.l2_loss(fc_weight)) \n",
    "\n",
    "x = tf.concat([hyp, evi], 1) # N, (Lh+Le), d\n",
    "# Permuting batch_size and n_steps\n",
    "x = tf.transpose(x, [1, 0, 2]) # (Le+Lh), N, d\n",
    "# Reshaping to (n_steps*batch_size, n_input)\n",
    "x = tf.reshape(x, [-1, vector_size]) # (Le+Lh)*N, d\n",
    "# Split to get a list of 'n_steps' tensors of shape (batch_size, n_input)\n",
    "x = tf.split(x, l_seq,)\n",
    "\n",
    "# x: the inputs to the bidirectional_rnn\n",
    "\n",
    "\n",
    "# tf.contrib.rnn.static_bidirectional_rnn: Runs the input through\n",
    "#   two recurrent networks, one that runs the inputs forward and one\n",
    "#   that runs the inputs in reversed order, combining the outputs.\n",
    "rnn_outputs, _, _ = tf.contrib.rnn.static_bidirectional_rnn(lstm, lstm_back,\n",
    "                                                            x, dtype=tf.float32)\n",
    "# rnn_outputs: the list of LSTM outputs, as a list. \n",
    "#   What we want is the latest output, rnn_outputs[-1]\n",
    "\n",
    "classification_scores = tf.matmul(rnn_outputs[-1], fc_weight) + fc_bias\n",
    "# The scores are relative certainties for how likely the output matches\n",
    "#   a certain entailment: \n",
    "#     0: Positive entailment\n",
    "#     1: Neutral entailment\n",
    "#     2: Negative entailment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to test the accuracy and begin to add in optimization constraints, we need to show TensorFlow how to calculate the accuracy, or -- the percentage of correctly predicted labels.\n",
    "\n",
    "We also need to determine a loss, to show how poorly the network is doing. Since we have both classification scores and optimal scores, the choice here is using a variation on softmax loss from Tensorflow: tf.nn.softmax_cross_entropy_with_logits. We add in regularization losses to help with overfitting, and then prepare an optimizer to learn how to reduce the loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with tf.variable_scope('Accuracy'):\n",
    "    predicts = tf.cast(tf.argmax(classification_scores, 1), 'int32')\n",
    "    y_label = tf.cast(tf.argmax(y, 1), 'int32')\n",
    "    corrects = tf.equal(predicts, y_label)\n",
    "    num_corrects = tf.reduce_sum(tf.cast(corrects, tf.float32))\n",
    "    accuracy = tf.reduce_mean(tf.cast(corrects, tf.float32))\n",
    "\n",
    "with tf.variable_scope(\"loss\"):\n",
    "    cross_entropy = tf.nn.softmax_cross_entropy_with_logits(\n",
    "        logits = classification_scores, labels = y)\n",
    "    loss = tf.reduce_mean(cross_entropy)\n",
    "    total_loss = loss + weight_decay * tf.add_n(\n",
    "        tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES))\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "\n",
    "opt_op = optimizer.minimize(total_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can train the network! If you installed TQDM, you can use it to keep track of progress as the network trains.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                          | 0/782 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 0.0, Minibatch Loss= 1.197576, Training Accuracy= 0.29688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|█                                                                                | 10/782 [00:06<06:42,  1.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 10.0, Minibatch Loss= 1.093180, Training Accuracy= 0.41406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|██                                                                               | 20/782 [00:07<01:46,  7.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 20.0, Minibatch Loss= 1.095966, Training Accuracy= 0.37500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|███                                                                              | 29/782 [00:08<01:20,  9.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 30.0, Minibatch Loss= 1.092363, Training Accuracy= 0.39062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|████                                                                             | 39/782 [00:09<01:05, 11.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 40.0, Minibatch Loss= 1.087109, Training Accuracy= 0.39844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|█████                                                                            | 49/782 [00:10<01:15,  9.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 50.0, Minibatch Loss= 1.078278, Training Accuracy= 0.41406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|██████                                                                           | 59/782 [00:11<01:12,  9.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 60.0, Minibatch Loss= 1.093685, Training Accuracy= 0.38281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|███████▏                                                                         | 69/782 [00:12<01:15,  9.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 70.0, Minibatch Loss= 1.073741, Training Accuracy= 0.46094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|████████▎                                                                        | 80/782 [00:13<01:14,  9.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 80.0, Minibatch Loss= 1.081725, Training Accuracy= 0.42188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█████████▏                                                                       | 89/782 [00:14<01:07, 10.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 90.0, Minibatch Loss= 1.096485, Training Accuracy= 0.32031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|██████████▏                                                                     | 100/782 [00:15<00:58, 11.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 100.0, Minibatch Loss= 1.086969, Training Accuracy= 0.46094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|███████████▎                                                                    | 110/782 [00:16<00:59, 11.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 110.0, Minibatch Loss= 1.078715, Training Accuracy= 0.39062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|████████████▎                                                                   | 120/782 [00:17<01:06,  9.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 120.0, Minibatch Loss= 1.076859, Training Accuracy= 0.41406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█████████████▎                                                                  | 130/782 [00:18<00:59, 11.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 130.0, Minibatch Loss= 1.050064, Training Accuracy= 0.47656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|██████████████▎                                                                 | 140/782 [00:19<01:01, 10.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 140.0, Minibatch Loss= 1.078603, Training Accuracy= 0.38281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|███████████████▎                                                                | 150/782 [00:20<01:04,  9.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 150.0, Minibatch Loss= 1.080289, Training Accuracy= 0.42969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|████████████████▎                                                               | 159/782 [00:21<00:59, 10.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 160.0, Minibatch Loss= 1.079748, Training Accuracy= 0.40625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|█████████████████▍                                                              | 170/782 [00:22<01:03,  9.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 170.0, Minibatch Loss= 1.044328, Training Accuracy= 0.47656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██████████████████▍                                                             | 180/782 [00:23<00:55, 10.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 180.0, Minibatch Loss= 1.069372, Training Accuracy= 0.43750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|███████████████████▍                                                            | 190/782 [00:24<00:57, 10.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 190.0, Minibatch Loss= 1.069931, Training Accuracy= 0.42969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|████████████████████▍                                                           | 200/782 [00:26<01:52,  5.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 200.0, Minibatch Loss= 1.072635, Training Accuracy= 0.40625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|█████████████████████▍                                                          | 209/782 [00:27<01:09,  8.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 210.0, Minibatch Loss= 1.067821, Training Accuracy= 0.46094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██████████████████████▌                                                         | 220/782 [00:28<00:54, 10.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 220.0, Minibatch Loss= 1.055713, Training Accuracy= 0.42969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|███████████████████████▌                                                        | 230/782 [00:29<00:49, 11.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 230.0, Minibatch Loss= 1.086459, Training Accuracy= 0.39062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|████████████████████████▌                                                       | 240/782 [00:30<00:49, 11.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 240.0, Minibatch Loss= 1.055432, Training Accuracy= 0.41406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|█████████████████████████▌                                                      | 250/782 [00:31<00:49, 10.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 250.0, Minibatch Loss= 1.073822, Training Accuracy= 0.46094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|██████████████████████████▍                                                     | 259/782 [00:32<00:48, 10.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 260.0, Minibatch Loss= 1.086537, Training Accuracy= 0.40625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███████████████████████████▌                                                    | 269/782 [00:33<01:00,  8.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 270.0, Minibatch Loss= 1.089738, Training Accuracy= 0.35938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|████████████████████████████▋                                                   | 280/782 [00:34<00:51,  9.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 280.0, Minibatch Loss= 1.116859, Training Accuracy= 0.34375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|█████████████████████████████▋                                                  | 290/782 [00:35<00:51,  9.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 290.0, Minibatch Loss= 1.062038, Training Accuracy= 0.42969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|██████████████████████████████▌                                                 | 299/782 [00:36<00:47, 10.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 300.0, Minibatch Loss= 1.081955, Training Accuracy= 0.39062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███████████████████████████████▌                                                | 309/782 [00:37<00:40, 11.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 310.0, Minibatch Loss= 1.061981, Training Accuracy= 0.46094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████████████████████████████████▋                                               | 319/782 [00:38<00:40, 11.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 320.0, Minibatch Loss= 1.066509, Training Accuracy= 0.42188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|█████████████████████████████████▋                                              | 329/782 [00:39<00:39, 11.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 330.0, Minibatch Loss= 1.033466, Training Accuracy= 0.46094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|██████████████████████████████████▋                                             | 339/782 [00:40<00:41, 10.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 340.0, Minibatch Loss= 1.081463, Training Accuracy= 0.39844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|███████████████████████████████████▋                                            | 349/782 [00:41<00:41, 10.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 350.0, Minibatch Loss= 1.037040, Training Accuracy= 0.46094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████████████████████████████████████▊                                           | 360/782 [00:42<00:42,  9.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 360.0, Minibatch Loss= 1.056379, Training Accuracy= 0.46094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|█████████████████████████████████████▋                                          | 369/782 [00:43<00:41, 10.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 370.0, Minibatch Loss= 1.057255, Training Accuracy= 0.39844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|██████████████████████████████████████▊                                         | 379/782 [00:44<00:41,  9.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 380.0, Minibatch Loss= 1.066335, Training Accuracy= 0.42969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|███████████████████████████████████████▊                                        | 389/782 [00:45<00:36, 10.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 390.0, Minibatch Loss= 1.060596, Training Accuracy= 0.45312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|████████████████████████████████████████▊                                       | 399/782 [00:46<00:36, 10.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 400.0, Minibatch Loss= 1.073414, Training Accuracy= 0.37500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████████████████████████████████████████▊                                      | 409/782 [00:47<00:34, 10.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 410.0, Minibatch Loss= 1.036693, Training Accuracy= 0.52344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|██████████████████████████████████████████▊                                     | 419/782 [00:48<00:34, 10.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 420.0, Minibatch Loss= 1.054526, Training Accuracy= 0.46875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|███████████████████████████████████████████▉                                    | 429/782 [00:49<00:33, 10.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 430.0, Minibatch Loss= 1.041792, Training Accuracy= 0.43750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|████████████████████████████████████████████▉                                   | 439/782 [00:50<00:32, 10.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 440.0, Minibatch Loss= 1.065973, Training Accuracy= 0.48438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|██████████████████████████████████████████████                                  | 450/782 [00:51<00:31, 10.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 450.0, Minibatch Loss= 1.070905, Training Accuracy= 0.48438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|███████████████████████████████████████████████                                 | 460/782 [00:52<00:33,  9.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 460.0, Minibatch Loss= 0.995900, Training Accuracy= 0.53125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|████████████████████████████████████████████████                                | 470/782 [00:53<00:42,  7.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 470.0, Minibatch Loss= 1.040523, Training Accuracy= 0.43750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|█████████████████████████████████████████████████                               | 480/782 [00:55<00:32,  9.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 480.0, Minibatch Loss= 1.087605, Training Accuracy= 0.34375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████████████████████████████████████████████████                              | 489/782 [00:55<00:30,  9.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 490.0, Minibatch Loss= 1.071255, Training Accuracy= 0.36719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|███████████████████████████████████████████████████▏                            | 500/782 [00:57<00:26, 10.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 500.0, Minibatch Loss= 1.077791, Training Accuracy= 0.46094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|████████████████████████████████████████████████████▏                           | 510/782 [00:58<00:31,  8.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 510.0, Minibatch Loss= 1.065492, Training Accuracy= 0.45312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|█████████████████████████████████████████████████████                           | 519/782 [00:58<00:27,  9.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 520.0, Minibatch Loss= 1.034288, Training Accuracy= 0.49219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████████████████████████████████████████████████████▏                         | 530/782 [01:01<00:52,  4.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 530.0, Minibatch Loss= 1.059613, Training Accuracy= 0.49219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|███████████████████████████████████████████████████████▏                        | 540/782 [01:02<00:27,  8.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 540.0, Minibatch Loss= 1.046844, Training Accuracy= 0.48438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|████████████████████████████████████████████████████████▏                       | 549/782 [01:03<00:22, 10.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 550.0, Minibatch Loss= 1.073947, Training Accuracy= 0.42188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|█████████████████████████████████████████████████████████▎                      | 560/782 [01:04<00:29,  7.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 560.0, Minibatch Loss= 1.000610, Training Accuracy= 0.51562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|██████████████████████████████████████████████████████████▎                     | 570/782 [01:05<00:25,  8.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 570.0, Minibatch Loss= 1.100064, Training Accuracy= 0.38281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████████████████████████████████████████████████████████▏                    | 579/782 [01:06<00:21,  9.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 580.0, Minibatch Loss= 1.039620, Training Accuracy= 0.45312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|████████████████████████████████████████████████████████████▎                   | 590/782 [01:07<00:18, 10.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 590.0, Minibatch Loss= 1.011063, Training Accuracy= 0.48438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|█████████████████████████████████████████████████████████████▍                  | 600/782 [01:08<00:15, 11.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 600.0, Minibatch Loss= 1.032956, Training Accuracy= 0.50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|██████████████████████████████████████████████████████████████▍                 | 610/782 [01:09<00:15, 11.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 610.0, Minibatch Loss= 1.052874, Training Accuracy= 0.49219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████████████████████████████████████████████████████████████▍                | 620/782 [01:10<00:14, 11.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 620.0, Minibatch Loss= 1.013053, Training Accuracy= 0.51562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████████████████████████████████████████████████████████████▍               | 630/782 [01:11<00:12, 11.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 630.0, Minibatch Loss= 1.015764, Training Accuracy= 0.51562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|█████████████████████████████████████████████████████████████████▍              | 640/782 [01:12<00:11, 12.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 640.0, Minibatch Loss= 1.013794, Training Accuracy= 0.50781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|██████████████████████████████████████████████████████████████████▍             | 650/782 [01:13<00:10, 12.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 650.0, Minibatch Loss= 1.003082, Training Accuracy= 0.51562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|███████████████████████████████████████████████████████████████████▌            | 660/782 [01:14<00:11, 10.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 660.0, Minibatch Loss= 1.035607, Training Accuracy= 0.51562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████████████████████████████████████████████████████████████████▌           | 670/782 [01:15<00:09, 11.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 670.0, Minibatch Loss= 1.006713, Training Accuracy= 0.52344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|█████████████████████████████████████████████████████████████████████▌          | 680/782 [01:16<00:08, 11.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 680.0, Minibatch Loss= 1.034152, Training Accuracy= 0.42188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|██████████████████████████████████████████████████████████████████████▌         | 690/782 [01:17<00:08, 10.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 690.0, Minibatch Loss= 1.063977, Training Accuracy= 0.48438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|███████████████████████████████████████████████████████████████████████▌        | 700/782 [01:18<00:10,  7.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 700.0, Minibatch Loss= 1.028311, Training Accuracy= 0.50781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|████████████████████████████████████████████████████████████████████████▌       | 709/782 [01:19<00:07,  9.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 710.0, Minibatch Loss= 1.060620, Training Accuracy= 0.43750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████████████████████████████████████████████████████████████████████▋      | 720/782 [01:20<00:06,  9.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 720.0, Minibatch Loss= 1.050399, Training Accuracy= 0.46875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|██████████████████████████████████████████████████████████████████████████▌     | 729/782 [01:21<00:05, 10.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 730.0, Minibatch Loss= 0.977969, Training Accuracy= 0.56250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|███████████████████████████████████████████████████████████████████████████▋    | 740/782 [01:22<00:04,  8.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 740.0, Minibatch Loss= 1.026878, Training Accuracy= 0.48438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|████████████████████████████████████████████████████████████████████████████▌   | 749/782 [01:23<00:03, 10.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 750.0, Minibatch Loss= 1.055589, Training Accuracy= 0.48438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████████████████████████████████████████████████████████████████████████▋  | 759/782 [01:24<00:02, 10.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 760.0, Minibatch Loss= 1.041089, Training Accuracy= 0.54688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|██████████████████████████████████████████████████████████████████████████████▋ | 769/782 [01:25<00:01, 10.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 770.0, Minibatch Loss= 1.037535, Training Accuracy= 0.51562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████▋| 779/782 [01:26<00:00, 11.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 780.0, Minibatch Loss= 1.033966, Training Accuracy= 0.48438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 782/782 [01:26<00:00,  9.03it/s]\n"
     ]
    }
   ],
   "source": [
    "# Initialize variables\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# Use TQDM if installed\n",
    "tqdm_installed = False\n",
    "try:\n",
    "    from tqdm import tqdm\n",
    "    tqdm_installed = True\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# Launch the Tensorflow session\n",
    "# sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\n",
    "sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\n",
    "sess.run(init)\n",
    "\n",
    "# training_iterations_count: The number of data pieces to train on in total\n",
    "# batch_size: The number of data pieces per batch\n",
    "training_iterations = range(0,training_iterations_count,batch_size)\n",
    "if tqdm_installed:\n",
    "    # Add a progress bar if TQDM is installed\n",
    "    training_iterations = tqdm(training_iterations)\n",
    "\n",
    "for i in training_iterations:\n",
    "\n",
    "    # Select indices for a random data subset\n",
    "    batch = np.random.randint(data_feature_list[0].shape[0], size=batch_size)\n",
    "    \n",
    "    # Use the selected subset indices to initialize the graph's \n",
    "    #   placeholder values\n",
    "    hyps, evis, ys = (data_feature_list[0][batch,:],\n",
    "                      data_feature_list[1][batch,:],\n",
    "                      correct_scores[batch])\n",
    "    \n",
    "    # Run the optimization with these initialized values\n",
    "    sess.run([opt_op], feed_dict={hyp: hyps, evi: evis, y: ys})\n",
    "    # display_step: how often the accuracy and loss should \n",
    "    #   be tested and displayed.\n",
    "    if (i/batch_size) % display_step == 0:\n",
    "        # Calculate batch accuracy\n",
    "        acc = sess.run(accuracy, feed_dict={hyp: hyps, evi: evis, y: ys})\n",
    "        # Calculate batch loss\n",
    "        tmp_loss = sess.run(loss, feed_dict={hyp: hyps, evi: evis, y: ys})\n",
    "        # Display results\n",
    "        print(\"Iter \" + str(i/batch_size) + \", Minibatch Loss= \" + \\\n",
    "              \"{:.6f}\".format(tmp_loss) + \", Training Accuracy= \" + \\\n",
    "              \"{:.5f}\".format(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your network is now trained! You should see accuracies around 50-55%, which can be improved by careful modification of hyperparameters and increasing the dataset size to include the entire training set. Usually, this will correspond with an increase in training time.\n",
    "\n",
    "Feel free to modify the following code by inserting your own sentences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evidences = [\"I like dogs.\"]\n",
    "\n",
    "hypotheses = [\"Peopel don't like dogs.\"]\n",
    "\n",
    "sentence1 = [fit_to_size(np.vstack(sentence2sequence(evidence)[0]),\n",
    "                         (30, 50)) for evidence in evidences]\n",
    "\n",
    "sentence2 = [fit_to_size(np.vstack(sentence2sequence(hypothesis)[0]),\n",
    "                         (30,50)) for hypothesis in hypotheses]\n",
    "\n",
    "prediction = sess.run(classification_scores, feed_dict={hyp: (sentence1 * N),\n",
    "                                                        evi: (sentence2 * N),\n",
    "                                                        y: [[0,0,0]]*N})\n",
    "print([\"Positive\", \"Neutral\", \"Negative\"][np.argmax(prediction[0])]+\n",
    "      \" entailment\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, once we're done playing with our model, we'll close the session to free up system resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver = tf.train.Saver()\n",
    "saver.save(sess,r\"C:\\Users\\86151\\Desktop\\trained.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
